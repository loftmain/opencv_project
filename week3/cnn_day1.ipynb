{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy.linalg as lin\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "from keras import models\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inverse를 통한 mnist 학습\n",
    "- 신경망을 통한 mnist 학습\n",
    "- cnn통한 mnist 학습 \n",
    "- fashon mnist, fast db 학습\n",
    "- web 연동(한글, 스케치 인식)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  38 254\n",
      "  109   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  87 252\n",
      "   82   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 135 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 244 150\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  84 254  63\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 202 223  11\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  32 254 216   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  95 254 195   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 140 254  77   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  57 237 205   8   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 124 255 165   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 171 254  81   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  24 232 215   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 120 254 159   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 151 254 142   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 228 254  66   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  61 251 254  66   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 141 254 205   3   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  10 215 254 121   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   5 198 176  10   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "(60000,)\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "plt.imshow(X_train[2], cmap='gray')\n",
    "print(X_test.shape)\n",
    "plt.imshow(X_test[2], cmap='gray')\n",
    "print(X_test[2])\n",
    "print(y_train.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0], 784))\n",
    "X_test = X_test.reshape((X_test.shape[0], 784))\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_e = to_categorical(y_train)\n",
    "y_test_e = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 역행렬을 이용한 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = wx + b  \n",
    "\n",
    "1 = w2.3 + b*1  -> 2.3  1  [w   = [1  \n",
    "6 = w1.5 + b*1  -> 1.5  1   b]     6]  \n",
    "\n",
    "역행렬만 구해주면 됨.  \n",
    "\n",
    "- y = W x .[x 1].\n",
    "- A 60000 X 785(=784 + 1)  \n",
    "- W = int(A) * y  , where Y = 60000*10, W= 785X 10\n",
    "                                              2x 1\n",
    "- predict ([x 1] * W), where x = 1x784 w=785x10  , 1x10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.hstack(((X_train, np.ones((60000, 1))) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 10)\n",
      "[[ 7.44778176e-17  3.08116485e-17  6.24517735e-17 ... -1.88247215e-17\n",
      "  -9.68761667e-17  2.74183832e-17]\n",
      " [ 6.37351236e-16 -2.76720495e-15 -2.38747509e-15 ...  1.19908305e-15\n",
      "   1.98622008e-15  1.90420431e-15]\n",
      " [ 5.70720542e-15  1.07908655e-14  1.08314732e-14 ... -1.04222601e-14\n",
      "  -1.36075550e-14 -4.14879462e-15]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.57799659e-01  2.41326501e-01  4.98284745e-02 ...  1.41540555e-01\n",
      "  -1.23002061e-01  4.55121243e-02]]\n",
      "Wall time: 11.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "W = np.matmul(lin.pinv(A), y_train_e)\n",
    "print(W.shape)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.44778176e-17  6.37351236e-16  5.70720542e-15 -6.89410182e-15\n",
      "  1.61921169e-15  6.01081563e-15  1.06678417e-15 -2.35600322e-15\n",
      " -1.58289428e-15  5.28664505e-15  1.76241660e-15  3.89576048e-15\n",
      "  3.02162834e-04  3.88864085e-04 -3.03538959e-04 -1.26474566e-05\n",
      " -5.69734437e-15  5.74454725e-15  8.25712682e-16  3.17557575e-15\n",
      " -9.67780512e-16  6.02280294e-15 -1.59623568e-15  3.28759776e-15\n",
      " -2.20570217e-15 -1.75501660e-15  3.72004608e-15 -2.80269838e-15\n",
      " -9.00127165e-16 -3.07402116e-15  5.85091557e-16  7.15061724e-15\n",
      " -7.99728688e-03  2.07102122e-03  2.37473673e-04  4.17736615e-04\n",
      "  1.25130340e-04  5.21710603e-06  1.07704793e-04  2.28418868e-04\n",
      " -1.42711146e-04  5.35057295e-04 -3.19725195e-04  1.21111359e-04\n",
      "  3.70121319e-07  1.51179376e-04 -1.21512767e-04  3.00575592e-05\n",
      "  1.67712928e-04 -2.78002180e-04  4.66517424e-04  7.11096870e-05\n",
      "  1.78253451e-15 -5.74546886e-15  3.12809877e-15  1.83356068e-15\n",
      " -2.18639760e-15  3.36444272e-15 -1.63857575e-02  1.91555200e-02\n",
      "  1.04795930e-03 -1.56986064e-03 -3.71169798e-04  1.97923477e-04\n",
      " -1.03489093e-04 -1.60399945e-04 -1.46721004e-04  9.84888622e-05\n",
      " -9.66732482e-05 -2.79440473e-05 -6.65553169e-05  7.17296351e-06\n",
      " -2.17383580e-04 -5.07822085e-05 -8.58926487e-05 -9.23833524e-05\n",
      " -1.93558665e-04  1.98621476e-04 -3.31149411e-04  2.03063689e-04\n",
      " -4.82052406e-04  8.02762737e-04  4.02604847e-15  7.76922512e-16\n",
      "  4.74941517e-15  2.36358989e-15  7.75084757e-03 -3.51674323e-03\n",
      " -1.67052698e-04 -1.60136442e-04 -1.24635781e-04 -3.99626795e-06\n",
      "  4.61199826e-05 -1.21977986e-04 -6.63081194e-05  1.07380282e-04\n",
      " -1.16543665e-04  9.04777993e-05 -8.98521697e-05 -6.02590206e-05\n",
      " -3.44602479e-05 -8.02979084e-05 -2.02944740e-04 -9.00206667e-05\n",
      " -2.11970947e-04 -2.05992308e-04 -1.35818508e-04 -1.31569567e-04\n",
      "  2.12109577e-04 -2.19391639e-04  4.48420916e-04 -4.82201184e-15\n",
      " -1.38731800e-15  1.21386532e-03 -5.62391198e-04 -1.12340367e-04\n",
      "  1.43468397e-04 -2.31980970e-05 -4.02361695e-05 -9.77238831e-05\n",
      "  7.30840002e-05 -8.53763448e-05 -4.39076523e-05 -5.55138254e-05\n",
      "  3.26650189e-06  6.01521849e-05 -6.83266745e-05  7.66483300e-05\n",
      " -3.25811929e-05  7.43978351e-06 -4.75926041e-06  5.04595834e-05\n",
      " -1.35397032e-05  5.44761787e-05 -4.82383769e-05 -1.29865616e-04\n",
      " -1.26317088e-04 -7.02850796e-05 -4.76356413e-04  2.60255840e-03\n",
      " -3.27130266e-15  5.90433208e-16 -1.80091955e-03 -1.47745970e-04\n",
      " -2.73372871e-05 -7.91988216e-05  7.55321395e-05 -2.97878096e-05\n",
      " -5.75936025e-05 -4.81474203e-05 -3.85662321e-05  1.97750925e-06\n",
      " -4.40692014e-05  7.01923009e-05  2.18242779e-07  3.80922537e-05\n",
      "  1.91443040e-05  2.77645733e-05 -2.89715048e-05  3.72764513e-05\n",
      " -4.99206447e-05 -3.57362121e-05 -1.00197566e-04 -1.23353729e-04\n",
      " -4.63021951e-05 -5.63670456e-05 -2.19022740e-04 -1.75791411e-03\n",
      "  2.43627982e-16 -5.00323283e-03  3.47542133e-04  1.30962426e-05\n",
      "  3.70815538e-05 -5.67003814e-05  2.89431861e-05 -3.28074106e-05\n",
      "  3.64752391e-05 -5.27742502e-05 -4.34435171e-05 -2.08604477e-05\n",
      " -3.40793443e-06  4.48213016e-05  5.78681687e-06 -9.83259329e-06\n",
      "  2.35754679e-05 -2.21277418e-06  2.95175075e-05 -2.71516038e-05\n",
      "  5.45150928e-06  3.77053414e-05  1.14505511e-05 -7.48846725e-05\n",
      " -2.03855153e-04 -6.19027052e-05 -1.49586132e-04 -1.69287493e-04\n",
      " -5.94572589e-02 -1.08114757e-04 -6.14234899e-04  8.09611296e-05\n",
      " -2.53618405e-05  2.94623498e-05 -1.53618276e-05  8.64158618e-06\n",
      " -5.07646449e-05  7.03692490e-05 -3.10905406e-05  2.79272959e-05\n",
      "  2.82951227e-05  2.69693526e-05  7.23750637e-05  6.29908079e-05\n",
      "  3.60894576e-06  7.50199382e-05  4.21176308e-05  3.70622806e-05\n",
      " -4.11362922e-05 -1.37862177e-05  7.18259200e-06 -3.31667220e-05\n",
      " -2.14345264e-04 -9.20133749e-05 -6.61334514e-05  2.33668145e-04\n",
      "  1.51714750e-02  1.57656747e-04  6.29295653e-05 -7.45710839e-05\n",
      " -8.98032093e-06 -2.12154213e-05  7.41337522e-05 -2.00716983e-05\n",
      "  9.66605953e-06 -9.04677989e-06  2.35959456e-06 -2.53119198e-05\n",
      "  2.95747872e-05  8.10456832e-06  3.92393848e-05  3.55715069e-05\n",
      "  1.02281403e-04  2.76196196e-05  3.13010396e-05  1.94994892e-06\n",
      "  6.12871416e-05 -5.30364844e-05  2.42391020e-05 -1.82517774e-06\n",
      " -2.40690828e-04 -2.48557210e-04 -5.21694424e-05 -1.47015465e-04\n",
      " -1.23835663e-03  2.48687732e-04 -1.04256313e-04  8.75525904e-06\n",
      " -3.37474685e-05 -3.43487914e-05 -4.55276709e-06  4.43621628e-05\n",
      "  2.30131772e-05  9.81418733e-06  2.15077755e-05 -3.52713272e-05\n",
      " -1.24484116e-05  5.73022207e-05  5.06844021e-05  6.44379950e-05\n",
      "  8.38248864e-06  2.29945161e-05  1.71905124e-05  8.13860930e-05\n",
      "  2.07062426e-05  4.11787595e-05 -6.88693831e-05  5.24515719e-05\n",
      " -6.52545047e-05 -4.31331449e-04  7.09105674e-06 -1.45541669e-04\n",
      "  8.26720837e-04 -4.28897874e-04 -1.18410470e-05 -4.15453670e-05\n",
      "  8.62459563e-06  4.41230942e-05 -2.42819575e-06 -2.67936808e-05\n",
      " -3.19903486e-05  5.60788587e-05 -7.76028279e-06  2.15570607e-05\n",
      "  3.39442810e-05  1.78479629e-05  1.74376512e-05  5.97223627e-05\n",
      "  3.74563704e-05  7.07668289e-05  6.72589800e-05  1.55073700e-05\n",
      "  1.30911452e-04  6.47342907e-05  8.51443610e-05  1.47476426e-04\n",
      " -1.49602501e-04 -4.37966013e-04 -3.30686567e-04  7.62915027e-04\n",
      " -7.47198405e-04  5.84459196e-04 -1.10168760e-04 -6.72092395e-05\n",
      "  5.48994408e-06 -1.36730037e-04  1.87212471e-06  3.79422351e-05\n",
      "  2.01285690e-05 -2.53812420e-05  4.61682067e-05  2.85647250e-05\n",
      " -4.03522310e-05 -2.85722773e-06 -8.29663432e-05 -5.01187640e-05\n",
      " -4.09185491e-05  1.40679387e-06  1.93445132e-05  8.19547557e-05\n",
      "  3.93037193e-05  1.26029978e-04  2.90253288e-05  1.38584411e-04\n",
      "  2.10174059e-04 -6.69003426e-04  2.86398150e-05 -1.31597016e-03\n",
      "  2.61451104e-04 -4.65954532e-04 -1.47065010e-04  4.48176334e-05\n",
      " -1.47168822e-04 -1.96069767e-05  3.65200569e-05 -3.02984918e-05\n",
      "  3.87625714e-05  1.88414168e-05  3.43323642e-05 -4.53485387e-05\n",
      "  2.89604185e-05 -2.16487665e-05 -1.50012143e-04 -5.68507622e-05\n",
      " -8.38558167e-05 -6.58100367e-05 -7.30364603e-05 -5.63972537e-05\n",
      "  5.24847816e-05  3.20304942e-05  5.54198437e-05  2.52100279e-04\n",
      "  1.63609558e-04 -7.38546079e-05 -6.44387339e-04  1.38351877e-03\n",
      "  7.13866308e-04  1.39727393e-03  4.79110456e-05 -4.08694027e-06\n",
      " -2.51330233e-05 -2.11395228e-05 -4.08822847e-05  3.82743242e-05\n",
      " -4.36830158e-05  3.01690248e-05  1.97547427e-05  1.53452155e-05\n",
      " -5.51966745e-05 -8.14254791e-05 -1.01979713e-04 -5.15366890e-05\n",
      " -4.51659162e-05 -9.52711816e-05 -9.79567190e-05 -4.54061325e-05\n",
      " -8.90990858e-05  3.59286926e-05  1.73079203e-04  1.41019851e-04\n",
      " -1.88713690e-04  2.01194074e-07  2.33674108e-04 -8.08128810e-04\n",
      " -6.57584123e-04 -8.56376501e-04 -1.21715678e-04 -1.18092203e-04\n",
      " -2.72284269e-04  4.09866892e-05  7.70518214e-05  4.73281866e-05\n",
      "  2.84362501e-05  4.03055844e-05  9.83081589e-05  1.93411087e-07\n",
      " -8.44011968e-05  1.01379395e-05 -1.36753200e-04  1.10100434e-05\n",
      " -7.84186005e-05 -8.41115589e-05 -5.79157403e-05 -7.50884276e-05\n",
      "  3.64095054e-05  1.57759281e-04  6.17437462e-07  4.66367491e-05\n",
      "  5.78020938e-05 -1.02495440e-04 -1.16746270e-04  1.30002734e-03\n",
      " -8.41674255e-04  4.93668327e-04  3.42913238e-05 -6.12535250e-05\n",
      "  9.54193248e-05  1.11876759e-04 -7.19885481e-05  6.89813866e-05\n",
      "  6.50015770e-05  7.32947073e-05  6.21803640e-05 -2.82176888e-05\n",
      " -6.34394777e-05 -4.33558002e-05 -1.13363489e-04 -1.58921419e-05\n",
      " -9.72555432e-05 -7.86935166e-05 -5.81655643e-05 -2.78855628e-05\n",
      "  6.21653788e-05 -9.84347990e-06 -2.67758726e-06  5.04055710e-05\n",
      " -4.98432004e-05 -1.00806602e-04 -6.15053551e-05  2.90710099e-04\n",
      " -3.57919485e-03  1.02573834e-04  5.89235384e-04 -4.63835210e-04\n",
      "  1.47449363e-05  1.96654949e-05  5.76982509e-05  1.35690121e-05\n",
      "  5.34241531e-05  1.87499575e-05  4.13919772e-05 -1.99899690e-05\n",
      " -1.10182593e-04 -7.24555501e-05 -6.94086343e-05 -5.87586727e-05\n",
      " -8.02378573e-05 -8.79654332e-05 -1.09107678e-05  3.01996260e-05\n",
      "  2.72799527e-05  2.10861015e-05 -1.07369133e-04  4.83073204e-05\n",
      "  4.61424354e-05 -2.47396358e-05 -1.25178743e-04 -8.34024097e-04\n",
      "  2.03581541e-15 -2.52150285e-04 -3.66984628e-04 -5.39171340e-05\n",
      "  3.28594595e-05  4.75829629e-05  5.55488136e-05  4.88272211e-05\n",
      " -8.22825026e-06  2.99075250e-05  3.31192703e-05 -2.95033014e-05\n",
      " -2.83411650e-05 -8.69521990e-05 -1.09703107e-04 -9.40964324e-05\n",
      " -3.57011171e-05  2.14205838e-05  1.80972040e-06  4.26532710e-05\n",
      " -2.82959886e-05 -3.16447741e-05  1.06214986e-04 -4.74161246e-05\n",
      "  9.90987976e-06 -3.55031253e-05  3.23472882e-04  3.23458528e-03\n",
      " -4.29493205e-04 -2.62426297e-04  4.98821881e-04 -4.63646555e-04\n",
      " -9.39433590e-06  6.70625418e-05 -1.65100102e-05  7.96779507e-05\n",
      "  6.54014280e-05  7.83061448e-06 -1.53486455e-05  1.67147938e-05\n",
      " -5.20574037e-05 -3.58975971e-05 -6.00628332e-05  5.64557556e-06\n",
      " -2.56028825e-05 -2.22149495e-05 -2.81308910e-05 -2.37577153e-06\n",
      " -5.39874968e-05 -1.04279948e-05 -1.31378873e-05 -1.39102264e-04\n",
      "  1.27113397e-04 -6.80140627e-05 -3.76417048e-04 -2.42305464e-03\n",
      " -2.20003823e-03  4.75545433e-04 -1.79418198e-04  2.46796585e-05\n",
      " -1.26502795e-05 -5.32588656e-05  3.04109018e-05  4.89148412e-05\n",
      "  2.41089514e-05  6.77698766e-05 -1.03228524e-05  3.54410694e-05\n",
      "  2.59234103e-05  2.26927248e-05  4.65265714e-06 -2.34535929e-05\n",
      " -7.23222993e-06  4.44466967e-06  1.01203269e-07 -2.61585289e-05\n",
      "  1.41019787e-05 -1.70304475e-05  1.56519308e-06  2.51669828e-05\n",
      " -3.56149654e-05 -1.03728732e-04  8.03380654e-05  1.68467880e-03\n",
      "  2.18354878e-16  1.94194636e-03  1.98406984e-04 -2.01681416e-04\n",
      " -5.38875484e-05  3.36357573e-05 -3.13524519e-05 -7.70876083e-07\n",
      "  2.18738162e-05  3.21971301e-06  4.11079627e-05  1.11217198e-06\n",
      "  4.28854010e-05  2.48204061e-05  2.86419104e-07  1.30809455e-05\n",
      " -5.05429429e-05  1.62615140e-05 -3.84733299e-05  3.47964916e-06\n",
      " -3.66128638e-05  6.31524619e-05 -3.90242528e-05 -1.13397260e-04\n",
      "  1.61948330e-05  1.91769246e-04 -2.13953390e-04 -6.00773411e-04\n",
      "  7.04912947e-04 -2.03547133e-03 -6.02794584e-05 -1.25921903e-05\n",
      "  1.10267643e-04 -5.04174146e-05 -1.53524182e-05 -1.91836063e-05\n",
      " -1.81956226e-05  5.39118752e-05  3.33247861e-05  4.16506174e-05\n",
      " -1.53180198e-06 -2.45789413e-05  6.27655004e-06  5.26237686e-05\n",
      "  1.13175159e-05 -4.62044753e-05  1.23067646e-05 -1.68434613e-05\n",
      " -7.49460537e-06 -3.17518180e-05  2.32746726e-05 -8.55728489e-05\n",
      "  4.31449570e-05 -2.12560848e-05  5.13631048e-04  1.12474105e-03\n",
      "  6.82884417e-04 -2.01477202e-03 -3.45701645e-05  1.96891960e-05\n",
      " -2.27945626e-04  5.02561523e-05  6.39516313e-05  1.97348528e-05\n",
      "  1.08405949e-05  3.33858776e-05  5.50584007e-06  3.79470589e-05\n",
      "  2.89713228e-05  8.26915090e-05  2.13929054e-05 -3.00283624e-05\n",
      " -1.18391693e-05 -1.13381850e-05 -6.87409325e-05  3.20969075e-05\n",
      " -9.53847287e-05  3.99325457e-05  2.57655260e-05 -2.91483496e-05\n",
      "  3.57210592e-05  2.01150619e-05  6.94315259e-04  2.07644502e-03\n",
      " -8.86056121e-17  2.13862218e-16  2.46090247e-04 -4.57651034e-05\n",
      " -1.15265174e-04 -3.59717423e-06 -1.18465230e-04  4.98609990e-05\n",
      " -3.73981223e-05  2.57945946e-05  6.17748222e-06  4.20013938e-05\n",
      "  5.03610331e-05  6.69522960e-06  5.93388203e-05  7.41768090e-05\n",
      "  4.26014800e-05  4.16972440e-05 -3.51539270e-05 -4.33443784e-05\n",
      " -2.18468843e-05 -1.03856352e-04  1.79871380e-05  3.78121275e-06\n",
      "  3.20402432e-05 -2.87518371e-04 -1.19763268e-03  2.58925380e-17\n",
      "  2.75716052e-17  2.31250202e-17 -1.32060846e-03  3.28148555e-04\n",
      "  4.51511831e-05 -1.73791741e-04  1.42351142e-04 -7.05891447e-05\n",
      "  9.95853227e-06 -5.35973975e-05 -9.57280962e-06 -8.96245524e-05\n",
      " -2.73340391e-05 -3.53993989e-05 -6.22068377e-05 -2.70156572e-05\n",
      " -7.93542638e-06  8.10437320e-06  7.60505981e-05 -1.75287327e-05\n",
      "  8.74110253e-05  6.25353852e-06 -1.98707721e-04  5.30033544e-05\n",
      " -2.76414970e-04  4.87125247e-04  8.71598494e-03 -1.13022852e-17\n",
      " -2.55157340e-17  1.11056526e-17  1.12670771e-03  1.37610741e-04\n",
      " -2.88741313e-06 -2.67243784e-04 -1.08244059e-04 -2.06431308e-04\n",
      " -1.08403896e-04 -9.42340744e-05 -1.30631766e-04 -5.29546882e-05\n",
      " -1.27085906e-04 -6.04399780e-05 -8.64677616e-05 -2.15205043e-05\n",
      " -5.94400186e-05 -6.72513857e-05 -4.30938426e-05  2.19864959e-05\n",
      " -1.41100343e-04  1.60526147e-05  2.79564377e-04 -3.32834043e-04\n",
      " -3.57083887e-04 -9.74638377e-04 -8.32517105e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.81579483e-03\n",
      "  5.13178474e-04 -4.05008093e-04  1.49920491e-05 -1.79865937e-04\n",
      " -9.28648905e-05 -2.28605528e-04 -8.45094814e-05 -1.98725847e-04\n",
      " -6.61464405e-05 -1.76889607e-04 -9.18665952e-05 -1.91696632e-04\n",
      " -1.06160959e-04 -6.41972169e-05 -1.46068500e-04 -1.48565636e-05\n",
      "  1.67458465e-05 -3.05540166e-04 -1.24765415e-04 -5.17146138e-04\n",
      "  4.04189505e-03 -5.35366833e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  1.56676905e-03  4.97406377e-05 -7.40804763e-04  1.18338115e-04\n",
      " -2.52832227e-04 -2.22413739e-04 -6.82261922e-05 -3.52221131e-05\n",
      " -2.66557645e-04 -1.50467936e-05 -2.66197859e-04 -4.81558314e-05\n",
      " -8.47385509e-05 -2.25565847e-04 -8.79477540e-05  2.13637671e-05\n",
      " -2.01749150e-04  3.61712250e-04 -6.86466242e-04 -4.09034628e-03\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  1.57799659e-01]\n"
     ]
    }
   ],
   "source": [
    "print(W[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "T = np.hstack((X_test, np.ones((10000, 1)) ))\n",
    "p = np.matmul(T, W)\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "샘플 하나에 10개의 클래스가 나옴.\n",
    "\n",
    "argmax를 통해 최대값을 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "p = np.argmax(p, axis = 1)\n",
    "print(p.shape)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[2 2 2]\n",
      "[1 1 1]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3], \n",
    "              [7,8,9], \n",
    "              [4,5,6]])\n",
    "print(np.argmax(a))\n",
    "print(np.argmax(a, axis=1)) #각각의 행에서 최대값의 index를 출력\n",
    "print(np.argmax(a, axis=0)) #각각의 컬럼에서 최대값의 index를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x17069e29b88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1, :].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8603"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인식률 조사\n",
    "np.mean(p == y_test) # 1 0 1 0 -> 50%, so 평균하면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "바이어스에 대한 이야기  \n",
    "\n",
    "바이어스를 뺴면 원점을 지나는 직선을 구하게 된다.  \n",
    "\n",
    "데이터들이 원점 근처에 있으면 크게 차이 안날 수도 있지만  \n",
    "\n",
    "일반적이지 않다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이것을 히든 레이어가 없는 신경망으로 풀어보자\n",
    "\n",
    "퍼셉트론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='softmax')) # 출력층 10개, 활성함수 softmax -> 확률값으로 해석하기 위해\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 0.1 0.9 1.2    \n",
    "# -> \n",
    "# 0.1/(0.1+0.9+1.2) #정규화\n",
    "# exp(0.1) / (exp(0.1) + exp(0.9) + exp(1.2))  지수로그 + 정규화 -> 소프트맥스\n",
    "# 작은것은 더 작게하고 큰것은 더 크게하자라는 발상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 9.4673 - accuracy: 0.8428\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 6.0102 - accuracy: 0.8791\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 5.5454 - accuracy: 0.8834\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 5.4931 - accuracy: 0.8850\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 5.4219 - accuracy: 0.8873\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 5.3601 - accuracy: 0.8875\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 5.2586 - accuracy: 0.8879\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 5.1811 - accuracy: 0.8907\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 5.2502 - accuracy: 0.8899\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 5.1604 - accuracy: 0.8891\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e, # 원핫 인코팅된 y\n",
    "                epochs = 10, \n",
    "                verbose = 1, # 로그를 축약\n",
    "                batch_size=32) # 32개씩 랜덤하게 뽑음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.25394210351166\n",
      "Test accuracy: 0.9042999744415283\n"
     ]
    }
   ],
   "source": [
    "# 인식률 계산\n",
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "0.9043\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "p = model.predict(X_test)\n",
    "print(p.shape)\n",
    "p = np.argmax(p, axis=1)\n",
    "print(np.mean(p == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784차원 + 1 : 분류기당 785개 * 10 분류기 = 7850  \n",
    "\n",
    "input dim 784 * 10 + bias 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=784, activation='relu')) # 첫번째 레이어에만 input_dim 명시\n",
    "model.add(Dense(10, activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input size * 뉴런 수 + 뉴런 수  \n",
    "\n",
    "layer 1 = 784 * 5 + 5 = 3925  \n",
    "layer 2 = 5 * 10 + 10 = 60  \n",
    "\n",
    "784차원을 5차원으로 줄여 너무 줄임  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.2177 - accuracy: 0.9432\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1651 - accuracy: 0.9545\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.1472 - accuracy: 0.9584\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1350 - accuracy: 0.9621\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1288 - accuracy: 0.9633\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1281 - accuracy: 0.9644\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1236 - accuracy: 0.9666\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.1204 - accuracy: 0.9668\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.1231 - accuracy: 0.9664\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1219 - accuracy: 0.9678\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.1127 - accuracy: 0.9696\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.1061 - accuracy: 0.9708\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.1063 - accuracy: 0.9715\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.1065 - accuracy: 0.9721\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.1014 - accuracy: 0.9722\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0976 - accuracy: 0.9736\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0968 - accuracy: 0.9733\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0921 - accuracy: 0.9748\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0935 - accuracy: 0.9751\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0933 - accuracy: 0.9746\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0855 - accuracy: 0.9772\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0865 - accuracy: 0.9767\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0934 - accuracy: 0.9772\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0828 - accuracy: 0.9781\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0771 - accuracy: 0.9792\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0799 - accuracy: 0.9787\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0825 - accuracy: 0.9783\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 53us/step - loss: 0.0772 - accuracy: 0.9799\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0790 - accuracy: 0.9801\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 0.0798 - accuracy: 0.9799\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e, # 원핫 인코팅된 y\n",
    "                epochs = 30, \n",
    "                verbose = 1, # 로그를 축약\n",
    "                batch_size=100) # 32개씩 랜덤하게 뽑음\n",
    "# 이미 10번 했으면 epochs에 100 하면 사실상 110번 이미 한 것에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.33849329506664944\n",
      "Test accuracy: 0.9588000178337097\n"
     ]
    }
   ],
   "source": [
    "# 인식률 계산\n",
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정규화\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input 데이터를 정규화 하지 않는것은 성능에 영향을 미침  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
      " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
      " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
      "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
      "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
      " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
      " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
      " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
      "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망에서 이것이 중요한 이유는 이게 값이 크면 가중치를 구하기가 쉽지 않다.  \n",
    "\n",
    "그래서 정규화를 해줘야한다.  \n",
    "영상은 무조건 해줘야된다고 생각해라\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.3769 - accuracy: 0.8825\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1161 - accuracy: 0.9665 0s - loss:\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0863 - accuracy: 0.9750\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0685 - accuracy: 0.9802\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0565 - accuracy: 0.9834\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0466 - accuracy: 0.9866\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.0393 - accuracy: 0.9887\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0334 - accuracy: 0.9908\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0286 - accuracy: 0.9924\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0238 - accuracy: 0.9939\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0203 - accuracy: 0.9949\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0168 - accuracy: 0.9961\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0141 - accuracy: 0.9970\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 54us/step - loss: 0.0113 - accuracy: 0.9978\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0096 - accuracy: 0.9983\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0077 - accuracy: 0.9987\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 52us/step - loss: 0.0063 - accuracy: 0.9990\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.99 - 3s 51us/step - loss: 0.0052 - accuracy: 0.9994\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0040 - accuracy: 0.9996\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0033 - accuracy: 0.9996\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0047 - accuracy: 0.9991\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 70us/step - loss: 0.0029 - accuracy: 0.9996\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 73us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0029 - accuracy: 0.9993\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 67us/step - loss: 0.0044 - accuracy: 0.9989\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 71us/step - loss: 4.9603e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 4.1416e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 4.3889e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e, # 원핫 인코팅된 y\n",
    "                epochs = 30, \n",
    "                verbose = 1, # 로그를 축약\n",
    "                batch_size=100) # 32개씩 랜덤하게 뽑음\n",
    "# 이미 10번 했으면 epochs에 100 하면 사실상 110번 이미 한 것에 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화 시키면 수렴의 속도가 빨라지는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사진 -> 2D 신경망 -> 필터 학습 -> 신경망  \n",
    "\n",
    "## 컨볼루션 신경망 구조\n",
    "\n",
    "입력이미지 -> 컨볼루션 계층 -> 풀링 계층 -> 다층 신경망 계층"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# 60000 x 28 x 28  -> 60000 x 28 x 28 x 1\n",
    "# X_train = X_train.reshape((60000, 28, 28, 1))\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "# X_test = X_test.reshape((10000, 28, 28, 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "y_train_e = to_categorical(y_train)\n",
    "y_test_e = to_categorical(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# 정규화\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 네트워크 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape = (28,28,1), filters=50,\n",
    "                kernel_size = (3,3), strides=(1,1), padding='same'))\n",
    "# sample X 28 X 28 X 50\n",
    "model.add(Activation('relu')) # softmax는 기울기가 0이 되버리는 문제가 있어 안씀\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = adam, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9800)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               2509056   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,512,126\n",
      "Trainable params: 2,512,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# input -> 60000, 28, 28, 1\n",
    "# layer 1 -> ?, 28, 28, 50(필터수) \n",
    "# 파라미터라는 것은 학습해야하는 가중치의 개수이다. \n",
    "# 500 -> (커널 size 3*3) * 50(filter 수) + 50(bias)\n",
    "# 커널할 때는 바이어스가 큰 의미가 없다. 생략 가능하긴 함\n",
    "# layer dense(256)       2509056 = 9800 * 256 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약 251만개의 파라미터수를 추정해야 한다.  \n",
    "CNN은 컨볼루션 계층에서 파라미터를 키우기 때문에 디멘션이 늘어날 수 밖에 없다.  \n",
    "\n",
    "input -> 60000, 28, 28, 1  \n",
    "layer 1 -> ?, 28, 28, 50(필터수)   \n",
    "파라미터라는 것은 학습해야하는 가중치의 개수이다.   \n",
    "500 -> (커널 size 3*3) * 50(filter 수) + 50(bias)  \n",
    "커널할 때는 바이어스가 큰 의미가 없다. 생략 가능하긴 함  \n",
    "layer dense(256)       2509056 = 9800 * 256 + 256  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250905.6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(9800 * 256 + 256)/ 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape = (28,28,1), filters=50,\n",
    "                kernel_size = (3,3), strides=(1,1), padding='same'))\n",
    "# sample X 28 X 28 X 50\n",
    "model.add(Activation('relu')) # softmax는 기울기가 0이 되버리는 문제가 있어 안씀\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=30,\n",
    "                kernel_size = (3,3), strides=(1,1), padding='same'))\n",
    "# sample X 28 X 28 X 50\n",
    "model.add(Activation('relu')) # softmax는 기울기가 0이 되버리는 문제가 있어 안씀\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = adam, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 28, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 30)        13530     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 14, 14, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1470)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               376576    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 393,176\n",
      "Trainable params: 393,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13530 = (3*3)* 50(채널 수) * 30 + 30  \n",
    "이미지 한장당 필터가 존재하는 것을 생각  \n",
    "\n",
    "보면 CNN 단에서의 파라미터는 이미지의 크기와는 상관이없다.  \n",
    "\n",
    "마지막 출력되는 영상의 크기 (None, 7, 7, 30)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13530"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3*3)*50 * 30 + 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape = (28,28,1), filters=50,\n",
    "                kernel_size = (3,3), strides=(1,1), padding='same'))\n",
    "# sample X 28 X 28 X 50\n",
    "model.add(Activation('relu')) # softmax는 기울기가 0이 되버리는 문제가 있어 안씀\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "             optimizer = adam, metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 53s 1ms/step - loss: 0.0689 - accuracy: 0.9797 - val_loss: 0.0641 - val_accuracy: 0.9805\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 55s 1ms/step - loss: 0.0425 - accuracy: 0.9869 - val_loss: 0.0543 - val_accuracy: 0.9841\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 55s 1ms/step - loss: 0.0288 - accuracy: 0.9914 - val_loss: 0.0519 - val_accuracy: 0.9844\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 67s 1ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.0537 - val_accuracy: 0.9835\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.0154 - accuracy: 0.9954 - val_loss: 0.0576 - val_accuracy: 0.9847\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 59s 1ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.0535 - val_accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 63s 1ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0657 - val_accuracy: 0.9827\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 68s 1ms/step - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0622 - val_accuracy: 0.9861\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 59s 1ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 0.0621 - val_accuracy: 0.9852\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 55s 1ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.0547 - val_accuracy: 0.9866\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x = X_train, y = y_train_e, # 원핫 인코팅된 y\n",
    "                batch_size = 100,\n",
    "                validation_split = 0.2, epochs = 10, verbose = 1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9869999885559082\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 50)        22550     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               627456    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 653,076\n",
      "Trainable params: 653,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape = (28,28,1), filters = 50, \n",
    "                 kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 50, \n",
    "                 kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = adam, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 80s 1ms/step - loss: 0.1648 - accuracy: 0.9499\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 81s 1ms/step - loss: 0.0446 - accuracy: 0.9863\n",
      "Test accuracy: 0.9886000156402588\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_e, \n",
    "                    batch_size = 100, epochs = 2, verbose = 1)\n",
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 50)        22550     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 30)          13530     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 7, 30)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 270)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               27100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 64,690\n",
      "Trainable params: 64,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape = (28,28,1), filters = 50, \n",
    "                 kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 50, \n",
    "                 kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(filters = 30, \n",
    "                 kernel_size = (3,3), strides = (1,1), padding = 'same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.001)\n",
    "model.compile(loss = 'categorical_crossentropy', \n",
    "              optimizer = adam, metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 86s 1ms/step - loss: 0.2363 - accuracy: 0.9281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_e, \n",
    "                    batch_size = 100, epochs = 1, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9800999760627747\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test_e, verbose=0)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_cnn_tiny.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('mnist_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 50)        22550     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               627456    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 653,076\n",
      "Trainable params: 653,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.3219467e-07 9.9969041e-01 2.4537053e-08 2.4274223e-09 2.2979428e-04\n",
      "  2.0367984e-06 5.6388639e-05 9.1706903e-07 2.0118532e-05 6.8794741e-08]]\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b8c16b5d48>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4차원으로 넣어주어야함\n",
    "import cv2\n",
    "img = cv2.imread('mnist_test/1_2.png', 0) / 255\n",
    "img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "p = model.predict(img)\n",
    "print(p)\n",
    "print(np.argmax(p))\n",
    "plt.plot(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 28, 50)        500       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 28, 28, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 50)        22550     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 30)          13530     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 7, 7, 30)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 3, 3, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 270)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               27100     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 64,690\n",
      "Trainable params: 64,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('mnist_cnn_tiny.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.6685338e-07 7.2600401e-06 9.9775273e-01 4.1357352e-04 7.0739337e-10\n",
      "  4.1648100e-08 7.1301458e-11 1.4702983e-06 1.8245631e-03 2.2671122e-08]]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b8bf7b3088>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread('mnist_test/2_2.png', 0) / 255\n",
    "img = img.reshape(1, 28, 28, 1)\n",
    "\n",
    "p = model.predict(img)\n",
    "print(p)\n",
    "print(np.argmax(p))\n",
    "plt.plot(p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글인식\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('hand_written_korean_classification.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 980)               502740    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 980)               0         \n",
      "=================================================================\n",
      "Total params: 1,748,468\n",
      "Trainable params: 1,748,468\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20d03ef9bc8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('mnist_test/na.png')\n",
    "image = (255 - image) / 255\n",
    "plt.imshow(image)\n",
    "# p = model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    }
   ],
   "source": [
    "image = image.reshape(1, 32, 32, 3)\n",
    "p = model.predict(image)\n",
    "p = np.argmax(p)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'나'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "labels_file = io.open(\"label.txt\", 'r', encoding='utf-8').read().split()\n",
    "label = [str for str in labels_file]\n",
    "label[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
